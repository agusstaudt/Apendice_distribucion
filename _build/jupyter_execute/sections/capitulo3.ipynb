{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Capítulo 3 \n",
    "\n",
    "## Rutina de Python para replicar el \"Apéndice en la Práctica\" del capítulo 3 de Pobreza y Desigualdad en América Latina \n",
    "#### Ultima actualización: 03 de agosto de 2022\n",
    "\n",
    "Códigos escritos en base a los apéndices del libro “Pobreza y Desigualdad en América Latina” de Gasparini, Cicowiez y Sosa Escudero. El objeto de este material es reproducir la rutina de códigos para STATA presentada en el libro al lenguaje *Python*. Este material es sólo de carácter complementario a las explicaciones y detalles conceptuales que se presentan en el libro de texto y los apéndices.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Set inicial\n",
    "\n",
    "Antes de comenzar, se cargan las librerías necesarias para poder desarrollar el capítulo:\n",
    "- *os*: realizar consultas acerca de directorios o pedidos específicos al sistema opertivo.\n",
    "- *pandas*: necesario para manipulación y análisis de datos.\n",
    "- *matplotlib*: para visualización.\n",
    "- *numpy*: para creación y manipulación de vectores y matrices. También presenta una gran colección de funciones matemáticas para operar con ellas.\n",
    "- *math*: para utilizar también funciones matemáticas.\n",
    "- *scipy*: herramientas y algoritmos matemáticos. contiene módulos para optimización, álgebra lineal, integración, interpolación, funciones especiales.\n",
    "- *econtools*: herramientas econométricas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: econtools in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\usuario\\appdata\\roaming\\python\\python310\\site-packages (from econtools) (1.23.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from econtools) (1.8.1)\n",
      "Requirement already satisfied: pandas>=0.16.0 in c:\\users\\usuario\\appdata\\roaming\\python\\python310\\site-packages (from econtools) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.16.0->econtools) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=0.16.0->econtools) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.16.0->econtools) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Importamos librerias de Python necesarias para replicar los calculos\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "!pip install econtools\n",
    "import econtools\n",
    "import econtools.metrics as mt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el capítulo 2, utilizamos colores para la ejecución de `print()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos algunos estilos \n",
    "class style():\n",
    "    black = '\\033[30m'\n",
    "    red = '\\033[31m'\n",
    "    green = '\\033[1;32m' # negrita\n",
    "    underline = '\\033[4m'\n",
    "    mark = '\\33[44m'\n",
    "    italic = '\\33[3;32m'\n",
    "    endc = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación cargamos las bases que vamos a utilizar. Se importan los archivos desde *google drive* de la misma manera que en el capítulo 2, con la diferencia de que al ser bases para diferentes países primero armamos una lista con los *id* de las bases que necesitamos, y las cargas se guardan en un diccionario de *python*. Los diccionarios aquí nos permiten crear mapeos a partir de una *key* y *values*, donde a partir de un nombre clave podemos almacenar listas o incluso un dataframe entero. Los mismos resultan muy útiles para problemas como el de almacenar diferentes *dataframes* en un solo lugar. Para más información acerca de diccionarios pueden consultar [***freeCodeCamp***](https://www.freecodecamp.org/espanol/news/compresion-de-diccionario-en-python-explicado-con-ejemplos/#:~:text=%C2%BFQu%C3%A9%20es%20un%20diccionario%20en,un%20par%20de%20corchetes%20%7B%7D%20.). Los diccionarios tienen la siguiente forma:    \n",
    "\n",
    "`mi_diccionario = {\"key1\":<value1>,\"key2\":<value2>,\"key3\":<value3>,\"key4\":<value4>}`\n",
    "\n",
    "Donde cada *value* puede referirse a un vector o base de datos. Para el siguiente bucle, cada *dataframe* cargado se guardará en *df_todos*. Nada nuevo a lo que venimos realizando, con la excepción de la función `sleep()` de la librería `time`. Google maneja ciertos límites para realizar sucesivas *queries* o pedidos, por lo que dada cierta repetición de solicitudes en un período corto de tiempo *python* podría arrojarnos un error. Por lo que en cada iteración pausamos el tiempo por la cantidad de segundos indicado en el bucle, en nuestro caso demoramos el proceso 4 segundos por repetición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration0: \u001b[1;32mdf_ecu\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration1: \u001b[1;32mdf_mex\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration2: \u001b[1;32mdf_nic\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration3: \u001b[1;32mdf_per\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration4: \u001b[1;32mdf_pan\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(links)):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miteration\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;241m.\u001b[39mgreen\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdfs[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;241m.\u001b[39mendc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     df_todos[dfs[i]] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://drive.google.com/uc?id=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlinks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     10\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m4\u001b[39m) \u001b[38;5;66;03m# restringimos la velocidad de cada query  \u001b[39;00m\n\u001b[0;32m     11\u001b[0m df_todos\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\stata.py:2022\u001b[0m, in \u001b[0;36mread_stata\u001b[1;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator, compression, storage_options)\u001b[0m\n\u001b[0;32m   2019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader:\n\u001b[1;32m-> 2022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\stata.py:1720\u001b[0m, in \u001b[0;36mStataReader.read\u001b[1;34m(self, nrows, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, typ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtyplist):\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(typ) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m-> 1720\u001b[0m         data[col] \u001b[38;5;241m=\u001b[39m data[col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode, convert_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1722\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_strls(data)\n\u001b[0;32m   1724\u001b[0m cols_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere([dtyp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m dtyp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtyplist])[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3654\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   3825\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3830\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   3831\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3832\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3835\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   3836\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3837\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   3838\u001b[0m     ):\n\u001b[0;32m   3839\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   3840\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:4532\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4530\u001b[0m \u001b[38;5;66;03m# We should never get here with DataFrame value\u001b[39;00m\n\u001b[0;32m   4531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Series):\n\u001b[1;32m-> 4532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reindex_for_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m   4535\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:10996\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  10992\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reindex_for_setitem\u001b[39m(value: DataFrame \u001b[38;5;241m|\u001b[39m Series, index: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m  10993\u001b[0m     \u001b[38;5;66;03m# reindex if necessary\u001b[39;00m\n\u001b[0;32m  10995\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mequals(index) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m> 10996\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10998\u001b[0m     \u001b[38;5;66;03m# GH#4107\u001b[39;00m\n\u001b[0;32m  10999\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cargamos las bases\n",
    "df_todos = {}\n",
    "links = [\"1fgHKvdLDe3x5tCQheoXRL1JMGNDW0W7n\", \"1udEv9SNL9IiOCmfXg8MLdru1v9C_Sds2\",\n",
    "        \"1ZBX4B4IrGPGIN9VwZLknaddCJ4AqAE07\", \"1f5p2qF1N9tgqoQ-bdY8QMvzSnt2FCFWY\",\n",
    "        \"1-a7OTv-I6SJXDhFhrCixbitx7KT4_lgx\"]\n",
    "dfs = [\"df_ecu\", \"df_mex\", \"df_nic\", \"df_per\", \"df_pan\"]\n",
    "for i in range(0, len(links)):\n",
    "    print(f'iteration{i}: {style.green}{dfs[i]}{style.endc}')\n",
    "    df_todos[dfs[i]] = pd.read_stata('https://drive.google.com/uc?id=' + links[i]) \n",
    "    time.sleep(4) # restringimos la velocidad de cada query  \n",
    "df_todos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Cociente de quintiles\n",
    "\n",
    "[***Páginas 151-152***](https://drive.google.com/file/d/1MwQrMylnYL0VHrLRM3JafsCBE9NkisAJ/view)\n",
    "\n",
    "El siguiente bloque de código puede utilizarse para computar el cociente de quintiles extremos presentado en el cuadro 3.2 del texto del libro, el cual es un indicador de desigualdad extendido en la literatura, que denota la magnitud de las brechas entre los más ricos y más pobres. Para realizar el cálculo se trabaja sobre un bucle que va a iterar sobre cada una de las bases importadas. En primer lugar, se filtra del diccionario el *dataframe* de interés denominado *df* y se eliminan las observaciones *ipcf* nulas para luego ordenarlas de manera ascendente con `sort_values()`. Posteriormente, se crea la proporción de población acumulada *shrpop* utilizando el factor de expansión *pondera*, ya que a partir de *shrpop* podemos identificar los 5 quintiles. La variable *quintil* vale 1 para el 20% más pobre de la población, 2 para el 20% siguiente, y así sucesivamente. Una vez obtenida la variable *quintil* computamos el ingreso promedio ponderado para las observaciones del quintil 1 y 5. En el cálculo de los *ipcf* promedios le indicamos a python con `loc()` que solo queremos quedarnos con las observaciones del quintil 1 (en *meadia_q1*) y el quintil 5 (en *media_q5*). A partir de la generación del *ipcf* promedio para ambos quintiles pasamos a calcular el ratio de estos dos valores e imprimimos el resultado con la función `print()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando \u001b[3;32mdf_ecu\u001b[0m el cociente de quintiles es igual a \u001b[1;32m20\u001b[0m\n",
      "Utilizando \u001b[3;32mdf_mex\u001b[0m el cociente de quintiles es igual a \u001b[1;32m13\u001b[0m\n",
      "Utilizando \u001b[3;32mdf_nic\u001b[0m el cociente de quintiles es igual a \u001b[1;32m15\u001b[0m\n",
      "Utilizando \u001b[3;32mdf_per\u001b[0m el cociente de quintiles es igual a \u001b[1;32m14\u001b[0m\n",
      "Utilizando \u001b[3;32mdf_pan\u001b[0m el cociente de quintiles es igual a \u001b[1;32m23\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Calculamos el cociente de quintiles para todas las base\n",
    "for name in dfs: \n",
    "    # Ordenar las observaciones del dataframe segun el IPCF\n",
    "    df = df_todos[name]\n",
    "    df = df[df[\"ipcf\"]>0]\n",
    "    df = df.sort_values(by=['ipcf'])\n",
    "\n",
    "    # Creamos una variable con la proporcion de poblacion acumulada\n",
    "    df.loc[:,\"shrpop\"] = df[\"pondera\"].cumsum()\n",
    "    df[\"shrpop\"]= df[\"shrpop\"]/ df[\"pondera\"].sum()\n",
    "\n",
    "    # Identificamos quintiles del IPCF\n",
    "    df.loc[(df[\"shrpop\"]>=0 & (df[\"shrpop\"]<=0.2)),\"quintil\"]=1\n",
    "    df.loc[(df[\"shrpop\"]>0.2) & (df[\"shrpop\"]<=0.4),\"quintil\"]=2\n",
    "    df.loc[(df[\"shrpop\"]>0.4) & (df[\"shrpop\"]<=0.6),\"quintil\"]=3\n",
    "    df.loc[(df[\"shrpop\"]>0.6) & (df[\"shrpop\"]<=0.8),\"quintil\"]=4\n",
    "    df.loc[(df[\"shrpop\"]>0.8) & (df[\"shrpop\"]<=1),\"quintil\"]=5\n",
    "\n",
    "    # Calculamos el IPCF promedio de ese quintil\n",
    "    media_q1 = np.average(df.loc[df[\"quintil\"]==1, \"ipcf\"], \n",
    "                          weights=df.loc[df[\"quintil\"]==1, \"pondera\"])\n",
    "    \n",
    "    # Calculamos el IPCF promedio de ese quintil\n",
    "    media_q5 = np.average(df.loc[df[\"quintil\"]==5, \"ipcf\"], \n",
    "                          weights=df.loc[df[\"quintil\"]==5, \"pondera\"])\n",
    "\n",
    "    print('Utilizando', style.italic + name + style.endc,'el cociente de quintiles es igual a', style.green + \"{:.0f}\".format(media_q5/media_q1) + style.endc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores obtenidos indican que la mayor brecha de quintiles extremos se da en Panamá, cuyo quintil 5 es 23 veces más alto que el del quintil 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Replicar programa ratq51\n",
    "\n",
    "[***Páginas 153-154***](https://drive.google.com/file/d/1MwQrMylnYL0VHrLRM3JafsCBE9NkisAJ/view)\n",
    "\n",
    "En la siguientes líneas de código proponemos escribir una función que permite computar el cociente de quintiles extremos muy fácilmente. Se define una función llamada *ratq51* que tiene como argumento la variable a utilizar *x* y opcionalmente el ponderador *weight*. Notarán que a diferencia de la función en Stata aquí no se incluye ningún condicional dentro de los argumentos de la función, esto es debido a que la misma se realiza implícitamente al indicar la base de datos a utilizar. Como aprendimos antes, podemos filtrar las observaciones que queremos utilizar y ubicar la sentencia dentro del argumento data. Por ejemplo, si quisieramos realizar el cálculo sobre la región 1 podríamos hacer lo siguiente:\n",
    "\n",
    "`ratq51(df.loc[df['region']==1,:], ...)`\n",
    "\n",
    "La creación de `ratq51()` se realiza mediante un método alternativo al que vimos en `descriptive_stats()` del capítulo 2. Como argumento primero establecemos la base de datos que necesitará la función, denominado *data*, y a continuación la variable que nos interesa dentro del dataset indicado. ¿Podríamos haber pasado directamente el vector de interés a la función? Por supuesto que sí, el contenido de la función sería un poco diferente, pero se podría como alternativa. Aunque para mostrar otra forma de encarar la elaboración de una función, se decidió optar por un camino alterno, donde primero indicamos la base de datos y posteriormente los nombres de la columna que interesan para ejecutar la función. Esto se deriva en que necesitamos indicar obligatoriamente un *dataset* y una columna de interés que se encuentre dentro de este, lo cual será evaluado en primera instancia como error fatal. De no cumplirse esto, la función arrojará un error. En el caso del ponderador, este no corre la misma suerte que los argumentos explicados antes. El factor de expansión es opcional, por lo que al no indicarlo la función computará el ratio sin ponderar. Lo que sigue es exactamente lo mismo que calculamos en la rutina anterior, con la diferencia de que readaptamos el código para volver al procedimiento uno genérico. \n",
    "\n",
    "Un detalle no menor se encuentra también en la forma de definir la variable *x* y el ponderador *weight* como argumentos de la función. El hecho de definir a ambas como string con la opción `str` hace que la función automáticamente entienda a ambos como caracteres, en vez de algún otro *type*, por lo que en el desarrollo de la función cada vez que nombramos a los argumentos lo podemos hacer sin incluir las comillas `''`. Mientras que al ejecutar dicha función se especifican los nombres de las variables entre comillas `''`. Por último, al seguir la ejecución del ratio de quintiles extremos realizado antes la función estaría filtrando el dataframe con valores mayores a cero.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratq51(data, x:str = None, weight:str = None):\n",
    "    ### Errores fatales\n",
    "    # Falta especificar dataset\n",
    "    if data.empty:\n",
    "        raise ValueError('Falta asignar valor a x')\n",
    "    else:\n",
    "        pass\n",
    "    # Falta indicar una variable dentro del dataframe a utilizar\n",
    "    if x is None:\n",
    "        raise ValueError('Falta asignar valor a x')\n",
    "    else:\n",
    "        pass\n",
    "    # Como el ponderador es opcional, contemplamos ambas posibilidades\n",
    "    if weight is None:\n",
    "        df = data[x]\n",
    "        df[weight] = data[x]*0+1\n",
    "    else:\n",
    "        df = data.loc[:, [x, weight]]\n",
    "    # Creamos el shrpop  \n",
    "    df = df.sort_values(by=[x])\n",
    "    df = df[df[x]>0]\n",
    "    df.loc[:,\"shrpop\"]= df[weight].cumsum()\n",
    "    df[\"shrpop\"]= df[\"shrpop\"]/ df[weight].sum()\n",
    "    \n",
    "    # Identificar quintiles\n",
    "    df.loc[(df[\"shrpop\"]<=0.2) & (df[\"shrpop\"]>=0),\"quintil\"]=1\n",
    "    df.loc[(df[\"shrpop\"]>0.2) & (df[\"shrpop\"]<=0.4),\"quintil\"]=2\n",
    "    df.loc[(df[\"shrpop\"]>0.4) & (df[\"shrpop\"]<=0.6),\"quintil\"]=3\n",
    "    df.loc[(df[\"shrpop\"]>0.6) & (df[\"shrpop\"]<=0.8),\"quintil\"]=4\n",
    "    df.loc[(df[\"shrpop\"]>0.8) & (df[\"shrpop\"]<=1),\"quintil\"]=5\n",
    "    \n",
    "    # Calculamos el IPCF promedio de ese quintil\n",
    "    media_q1 = np.average(df.loc[df[\"quintil\"]==1, x], \n",
    "                          weights=df.loc[df[\"quintil\"]==1, weight])\n",
    "    \n",
    "    # Calculamos el IPCF promedio de ese quintil\n",
    "    media_q5 = np.average(df.loc[df[\"quintil\"]==5, x], \n",
    "                          weights=df.loc[df[\"quintil\"]==5, weight])\n",
    "\n",
    "    return media_q5/media_q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn' https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas\n",
    "#Volvemos a calcular el ratio para todas las bases pero utilizando la nueva funcion y almacenando los resultados en un df\n",
    "results = pd.DataFrame(columns = ['Pais', 'Año', 'Q5/Q1'])\n",
    "results['Pais'] = ['Ecuador', 'Mexico', 'Nicaragua', 'Peru', 'Panama']\n",
    "results['Año'] = ['2006', '2006', '2005', '2006', '2006']\n",
    "\n",
    "j = 0\n",
    "\n",
    "for name in dfs:    \n",
    "    df = df_todos[name]\n",
    "    results.iloc[j]['Q5/Q1'] = ratq51(data = df, x ='ipcf', weight = 'pondera')\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pais</th>\n",
       "      <th>Año</th>\n",
       "      <th>Q5/Q1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ecuador</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>2005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peru</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Panama</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pais   Año Q5/Q1\n",
       "0    Ecuador  2006   NaN\n",
       "1     Mexico  2006   NaN\n",
       "2  Nicaragua  2005   NaN\n",
       "3       Peru  2006   NaN\n",
       "4     Panama  2006   NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos que los resultados se hayan almacenado correctamente\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Replicar programa gcuan \n",
    "\n",
    "[***Páginas 154-155***](https://drive.google.com/file/d/1MwQrMylnYL0VHrLRM3JafsCBE9NkisAJ/view)\n",
    "\n",
    "El bloque de código a continuación permite identificar cuantiles de cualquier variable. En términos de la función `ratq51()` nos permite generar variables similares al quintil pero que pueden identificar también deciles, ventiles, percentiles, etc. \n",
    "\n",
    "Por esta razón, esta función tendrá más argumentos, aquí además de los anteriores debemos detallar la cantidad de cuantiles a generar (argumento *num*) y la variable que los almacena (*newvar*). Esta última tendrá como nombre por defecto *'cuantil'*, pero el usuario podría asignar el nombre que desea (siempre entre comillas). Notar que aquí *weight* sigue siendo opcional, de no agregarse el código realizará los cálculos sin factor de expansión. No obstante, la forma de comprobar la existencia del ponderador se realiza a través de la función `len()`, que verifica si hay una longitud positiva de la serie que se va a utilizar como factor de expansión, la cual representa una manera alternativa de realizar el chequeo.    \n",
    "\n",
    "Luego el código y la secuencia son idénticos a la de la función anterior, salvo que aquí el objeto “num” indica cuantos cuantiles deben generarse, haciendo iterar al bucle “num” cantidad de veces, y define los intervalos de población acumulada de forma equivalente. Por ejemplo, si queremos generar deciles (num=10), necesitamos 10 cuantiles y cada cuantil se asigna en intervalos de población acumulada iguales a 0.10 (1/10). Una vez identificado los cuantiles `gcuan()` computa la media, el desvío estándar y la cantidad de observaciones para cada cuantil y asigna los resultados a un *dataframe* llamado *result*, el cual es impreso como output de la función,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcuan(x, num: int, weight, newvar = 'cuantil'):\n",
    "    dict = {}\n",
    "    if int(num)!= num:\n",
    "        raise ValueError('Los cuantiles tienen que ser números enteros')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if len(weight)==0:\n",
    "        weight = x*0+1\n",
    "    else:\n",
    "        weight = weight \n",
    "\n",
    "    df = pd.concat([x, weight], axis=1, keys=['x', 'weight'])\n",
    "    df = df.sort_values(by=['x'])\n",
    "    df = df[df[\"x\"]>0]\n",
    "    df.loc[:,\"shrpop\"] = df[\"weight\"].cumsum()\n",
    "    df[\"shrpop\"] = df[\"shrpop\"]/df[\"weight\"].sum()    \n",
    "\n",
    "    shrcuantil = 1/num\n",
    "\n",
    "    df[newvar]=0\n",
    "\n",
    "    for i in range(1, num+1):\n",
    "        \n",
    "        df.loc[(df['shrpop']>(i-1)*shrcuantil) & (df['shrpop']<=i*shrcuantil), newvar] = i \n",
    "\n",
    "    result = pd.DataFrame({'mean':df.groupby([newvar], group_keys=False).apply(lambda x: np.average(x.x, weights=x.weight)),\n",
    "                          'std':df.groupby([newvar], group_keys=False).apply(lambda x: math.sqrt(np.average((x.x-np.average(x.x, weights=x.weight))**2, weights=x.weight))),\n",
    "                          'obs':df.groupby([newvar], group_keys=False).apply(lambda x: x.weight.sum())})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar la función, utilizamos el *dataframe* de México dentro del diccionario *df_todos*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>obs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuantil</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>499.297821</td>\n",
       "      <td>197.360522</td>\n",
       "      <td>20372798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011.521729</td>\n",
       "      <td>136.702824</td>\n",
       "      <td>20387336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1539.610107</td>\n",
       "      <td>172.706381</td>\n",
       "      <td>20381024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2382.652832</td>\n",
       "      <td>345.381707</td>\n",
       "      <td>20380795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6707.636230</td>\n",
       "      <td>6531.797609</td>\n",
       "      <td>20381791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean          std       obs\n",
       "cuantil                                    \n",
       "1         499.297821   197.360522  20372798\n",
       "2        1011.521729   136.702824  20387336\n",
       "3        1539.610107   172.706381  20381024\n",
       "4        2382.652832   345.381707  20380795\n",
       "5        6707.636230  6531.797609  20381791"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aplicamos la funcion creando 5 cuantiles en la base de Ecuador \n",
    "gcuan(df_todos['df_mex']['ipcf'], 5, weight=df_todos['df_mex']['pondera'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Tamaño de los hogares\n",
    "\n",
    "[***Páginas 156***](https://drive.google.com/file/d/1MwQrMylnYL0VHrLRM3JafsCBE9NkisAJ/view)\n",
    "\n",
    "El código siguiente puede utilizarse para computar las estadísticas sobre proporción de hogares unipersonales y multipersonales presentadas en el cuadro 3.4 del texto. Con este código podremos calcular qué proporción del total de hogares se compone de 1, 2, 3, 4,…, n miembros y combinado con los códigos anteriores, analizar cómo esta configuración cambia al agrupar por regiones, percentil de ingreso, condición de pobreza, etc. \n",
    "\n",
    "En primer lugar, cargamos las bases que vamos a utilizar, las cuales son representativas de los países de Honduras, México, República Dominicana y Uruguay. Las mismas son improtadas y guardadas en el diccionario *df_todos*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration0: \u001b[1;32mdf_hon\u001b[0m\n",
      "iteration1: \u001b[1;32mdf_mex\u001b[0m\n",
      "iteration2: \u001b[1;32mdf_dom\u001b[0m\n",
      "iteration3: \u001b[1;32mdf_ury\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'df_hon':             id                 depto  munic  numhog  com  \\\n",
       " 0      1002641  8. francisco morazan    1.0       1    1   \n",
       " 1      1002641  8. francisco morazan    1.0       1    4   \n",
       " 2      1002641  8. francisco morazan    1.0       1    3   \n",
       " 3      1002641  8. francisco morazan    1.0       1    2   \n",
       " 4      1005151  8. francisco morazan    1.0       1    1   \n",
       " ...        ...                   ...    ...     ...  ...   \n",
       " 99640  5185651              18. yoro   11.0       1    2   \n",
       " 99641  5185751              18. yoro   11.0       1    1   \n",
       " 99642  5185751              18. yoro   11.0       1    2   \n",
       " 99643  5185751              18. yoro   11.0       1    4   \n",
       " 99644  5185751              18. yoro   11.0       1    3   \n",
       " \n",
       "                           relacion  edad  totper  \\\n",
       " 0                1. jefe del hogar  40.0       4   \n",
       " 1                         3. hijos   8.0       4   \n",
       " 2                         3. hijos  11.0       4   \n",
       " 3                         3. hijos  21.0       4   \n",
       " 4                1. jefe del hogar  42.0       4   \n",
       " ...                            ...   ...     ...   \n",
       " 99640                     3. hijos   9.0       5   \n",
       " 99641            1. jefe del hogar  29.0       4   \n",
       " 99642  2. esposa(o) o compañera(o)  18.0       4   \n",
       " 99643                     3. hijos   0.0       4   \n",
       " 99644                     3. hijos   2.0       4   \n",
       " \n",
       "                                              p07  \\\n",
       " 0      33405 perito mercantil y contador público   \n",
       " 1                                            NaN   \n",
       " 2                                            NaN   \n",
       " 3                              67204 odontología   \n",
       " 4                63203 comunicación y publicidad   \n",
       " ...                                          ...   \n",
       " 99640                                        NaN   \n",
       " 99641                                        NaN   \n",
       " 99642                                        NaN   \n",
       " 99643                                        NaN   \n",
       " 99644                                        NaN   \n",
       " \n",
       "                                 p08  ...   p_reg         ipc pipcf dipcf  \\\n",
       " 0      presencial en centro privado  ...  1.0000  159.300003   1.0   1.0   \n",
       " 1      presencial en centro público  ...  1.0000  159.300003   1.0   1.0   \n",
       " 2      presencial en centro público  ...  1.0000  159.300003   1.0   1.0   \n",
       " 3      presencial en centro público  ...  1.0000  159.300003   1.0   1.0   \n",
       " 4      presencial en centro privado  ...  1.0000  159.300003   1.0   1.0   \n",
       " ...                             ...  ...     ...         ...   ...   ...   \n",
       " 99640                           NaN  ...  0.8695  159.300003   NaN   NaN   \n",
       " 99641  presencial en centro público  ...  0.8695  159.300003   NaN   NaN   \n",
       " 99642  presencial en centro público  ...  0.8695  159.300003   NaN   NaN   \n",
       " 99643                           NaN  ...  0.8695  159.300003   NaN   NaN   \n",
       " 99644                           NaN  ...  0.8695  159.300003   NaN   NaN   \n",
       " \n",
       "       p_ing_ofi d_ing_ofi piea qiea iol ionl  \n",
       " 0           NaN       NaN  1.0  1.0 NaN  NaN  \n",
       " 1           NaN       NaN  1.0  1.0 NaN  NaN  \n",
       " 2           NaN       NaN  1.0  1.0 NaN  NaN  \n",
       " 3           NaN       NaN  1.0  1.0 NaN  NaN  \n",
       " 4           NaN       NaN  1.0  1.0 NaN  NaN  \n",
       " ...         ...       ...  ...  ...  ..  ...  \n",
       " 99640      17.0       2.0  NaN  NaN NaN  NaN  \n",
       " 99641      72.0       8.0  NaN  NaN NaN  NaN  \n",
       " 99642      72.0       8.0  NaN  NaN NaN  NaN  \n",
       " 99643      72.0       8.0  NaN  NaN NaN  NaN  \n",
       " 99644      72.0       8.0  NaN  NaN NaN  NaN  \n",
       " \n",
       " [99645 rows x 246 columns],\n",
       " 'df_mex':        edad     id  pondera  hombre  region  urbano  nivel           ipcf\n",
       " 0        97     38     1098       0       4       1    0.0       0.000000\n",
       " 1        23    108       98       1       4       0    2.0       0.000000\n",
       " 2        19    108       98       0       4       0    3.0       0.000000\n",
       " 3        72    161      638       0       4       1    0.0       0.000000\n",
       " 4        90    161      638       0       4       1    0.0       0.000000\n",
       " ...     ...    ...      ...     ...     ...     ...    ...            ...\n",
       " 81999    17  16587      607       0       1       0    3.0  109714.742188\n",
       " 82000    65  15205     1159       1       2       1    6.0  144282.562500\n",
       " 82001    61  15205     1159       0       2       1    3.0  144282.562500\n",
       " 82002    34  11028     2098       1       4       1    6.0  165842.015625\n",
       " 82003    48   8710      798       1       5       1    6.0  192500.000000\n",
       " \n",
       " [82004 rows x 8 columns],\n",
       " 'df_dom':       pais   ano           encuesta    id  com  pondera  relacion  hogarsec  \\\n",
       " 0      dom  2006  ENFT onda Octubre  2907    1      285         1         0   \n",
       " 1      dom  2006  ENFT onda Octubre  2998    1      190         1         0   \n",
       " 2      dom  2006  ENFT onda Octubre  2998    2      190         2         0   \n",
       " 3      dom  2006  ENFT onda Octubre  2998    4      190         3         0   \n",
       " 4      dom  2006  ENFT onda Octubre  2998    3      190         3         0   \n",
       " ...    ...   ...                ...   ...  ...      ...       ...       ...   \n",
       " 28650  dom  2006  ENFT onda Octubre  5117    1      412         1         0   \n",
       " 28651  dom  2006  ENFT onda Octubre  5117    2      412         2         0   \n",
       " 28652  dom  2006  ENFT onda Octubre  5117    4      412         3         0   \n",
       " 28653  dom  2006  ENFT onda Octubre  5117    3      412         3         0   \n",
       " 28654  dom  2006  ENFT onda Octubre  5117    5      412         5         0   \n",
       " \n",
       "        hogar  miembros  ...  lp_moderada  ing_pob_mod_lp   p_reg         ipc  \\\n",
       " 0        1.0         1  ...  2181.820068        0.000000  1.0000  248.800003   \n",
       " 1        1.0         4  ...  2181.820068        0.000000  1.0000  248.800003   \n",
       " 2        NaN         4  ...  2181.820068        0.000000  1.0000  248.800003   \n",
       " 3        NaN         4  ...  2181.820068        0.000000  1.0000  248.800003   \n",
       " 4        NaN         4  ...  2181.820068        0.000000  1.0000  248.800003   \n",
       " ...      ...       ...  ...          ...             ...     ...         ...   \n",
       " 28650    1.0         5  ...  2181.820068       89.599823  0.8695  248.800003   \n",
       " 28651    NaN         5  ...  2181.820068       89.599823  0.8695  248.800003   \n",
       " 28652    NaN         5  ...  2181.820068       89.599823  0.8695  248.800003   \n",
       " 28653    NaN         5  ...  2181.820068       89.599823  0.8695  248.800003   \n",
       " 28654    NaN         5  ...  2181.820068       89.599823  0.8695  248.800003   \n",
       " \n",
       "        pipcf  dipcf  p_ing_ofi  d_ing_ofi  piea  qiea  \n",
       " 0          1      1          1          1     1     1  \n",
       " 1          1      1          1          1     1     1  \n",
       " 2          1      1          1          1     1     1  \n",
       " 3          1      1          1          1     1     1  \n",
       " 4          1      1          1          1     1     1  \n",
       " ...      ...    ...        ...        ...   ...   ...  \n",
       " 28650    100     10        100         10   100     5  \n",
       " 28651    100     10        100         10   100     5  \n",
       " 28652    100     10        100         10   100     5  \n",
       " 28653    100     10        100         10   100     5  \n",
       " 28654    100     10        100         10   100     5  \n",
       " \n",
       " [28655 rows x 192 columns],\n",
       " 'df_ury':         correlativ  mes  dpto  region_ech  estrato  nper  ms36  mt26  \\\n",
       " 0             1064    1     1          14        4     1     0     0   \n",
       " 1             1064    1     1          14        4     2     0     0   \n",
       " 2            13630    7     1          11        1     1     2     0   \n",
       " 3            22042    4     1          12        2     1     0     0   \n",
       " 4            23077    6     1          12        2     1     0     0   \n",
       " ...            ...  ...   ...         ...      ...   ...   ...   ...   \n",
       " 177723      137127    4     3          19        9     2     0     0   \n",
       " 177724      137127    4     3          19        9     3     0     2   \n",
       " 177725      137169    4     1          13        3     2     0     0   \n",
       " 177726      137205    3     1          13        3     2     0     0   \n",
       " 177727      137340    3    18          17        7     2     0     0   \n",
       " \n",
       "         pobpcoac  pesotri  ...  lp_moderada  ing_pob_mod_lp   ipc_rel  p_reg  \\\n",
       " 0              4      103  ...  3397.221436        0.000000  1.000000      1   \n",
       " 1              6      103  ...  3397.221436        0.000000  1.000000      1   \n",
       " 2              4       31  ...  3456.151123        0.891666  1.038800      1   \n",
       " 3              4       57  ...  3586.987305        0.000000  1.023677      1   \n",
       " 4              2       57  ...  3652.507812        0.000000  1.035491      1   \n",
       " ...          ...      ...  ...          ...             ...       ...    ...   \n",
       " 177723         2      135  ...  2250.114746        2.645791  1.023677      1   \n",
       " 177724         2      135  ...  2250.114746        2.645791  1.023677      1   \n",
       " 177725         2       75  ...  3492.593018        4.312698  1.023677      1   \n",
       " 177726         2       75  ...  3575.131348        3.215546  1.020416      1   \n",
       " 177727         2       29  ...          NaN             NaN  1.020416      1   \n",
       " \n",
       "        pipcf  dipcf  p_ing_ofi  d_ing_ofi  piea  qiea  \n",
       " 0        1.0    1.0        1.0        1.0   1.0   1.0  \n",
       " 1        1.0    1.0        1.0        1.0   1.0   1.0  \n",
       " 2        1.0    1.0       22.0        3.0   1.0   1.0  \n",
       " 3        1.0    1.0        1.0        1.0   1.0   1.0  \n",
       " 4        1.0    1.0        1.0        1.0   1.0   1.0  \n",
       " ...      ...    ...        ...        ...   ...   ...  \n",
       " 177723   NaN    NaN       74.0        8.0   NaN   NaN  \n",
       " 177724   NaN    NaN       74.0        8.0   NaN   NaN  \n",
       " 177725   NaN    NaN       90.0        9.0   NaN   NaN  \n",
       " 177726   NaN    NaN       81.0        9.0   NaN   NaN  \n",
       " 177727   NaN    NaN        NaN        NaN   NaN   NaN  \n",
       " \n",
       " [177728 rows x 233 columns]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_todos = {}\n",
    "links = [\"1pLly5AnoWj9fPyBcBZ8bCgDWqZ1eppgD\", \"1udEv9SNL9IiOCmfXg8MLdru1v9C_Sds2\",\n",
    "        \"1BxiFvCMrUSjDsgYs73-1yi2cGMuKJV22\", \"1XI6dexijKCd2jIZlyZfV6C9sAU2mq39y\"]\n",
    "dfs = [\"df_hon\", \"df_mex\", \"df_dom\", \"df_ury\"]\n",
    "cnt = [\"Honduras\", \"México\", \"Rep. Dominicana\", \"Uruguay\"]\n",
    "for i in range(0, len(links)):\n",
    "    print(f'iteration{i}: {style.green}{dfs[i]}{style.endc}')\n",
    "    df_todos[dfs[i]] = pd.read_stata('https://drive.google.com/uc?id=' + links[i]) \n",
    "    time.sleep(4) # restringimos la velocidad de cada query  \n",
    "df_todos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, pasamos a calcular la proporción de hogares según tamaño o cantidad de integrantes para cada país. Para hacerlo, realizamos el siguiente procedimiento para cada país:\n",
    "1. ordenamos las observaciones según *id* de forma ascendente y jefe de hogar de manera descendente, e identificamos al primer integrante de cada hogar\n",
    "2. creamos una variable unitaria *aux* que utilizamos para sumar la cantidad de integrantes por hogar\n",
    "3. creamos la variable *tamanio* que va a representar la cantidad de miembros por hogar, truncando en 6, es decir, el valor 6 representará la condición `...>=6`\n",
    "4. una vez que creamos *tamanio* filtramos la base para quedarnos solamente con una observación del hogar, en nuestro caso la primera de cada *id* que sería el jefe de hogar. También, realizamos un filtro para quedarnos con hogares con al menos un miembro\n",
    "5. agregamos las observaciones por cantidad de miembros en el hogar, sumando cada observación utilizando su ponderador. Al quedarnos solamente con una observación por hogar esta suma equivale a la suma de hogares por cantidad de miembros. Luego, calculamos su frecuencia realtiva\n",
    "6. el output generado para cada país es unido a la base final *df_total*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration3: \u001b[1;32mdf_hon\u001b[0m\n",
      "iteration3: \u001b[1;32mdf_mex\u001b[0m\n",
      "iteration3: \u001b[1;32mdf_dom\u001b[0m\n",
      "iteration3: \u001b[1;32mdf_ury\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tamanio</th>\n",
       "      <th>Honduras</th>\n",
       "      <th>México</th>\n",
       "      <th>Rep. Dominicana</th>\n",
       "      <th>Uruguay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.153600</td>\n",
       "      <td>9.242860</td>\n",
       "      <td>12.293994</td>\n",
       "      <td>19.679599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.046661</td>\n",
       "      <td>15.038548</td>\n",
       "      <td>16.486744</td>\n",
       "      <td>26.300074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15.484209</td>\n",
       "      <td>18.716443</td>\n",
       "      <td>19.655375</td>\n",
       "      <td>20.714957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>18.804112</td>\n",
       "      <td>22.618685</td>\n",
       "      <td>20.578243</td>\n",
       "      <td>17.412574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18.067299</td>\n",
       "      <td>17.042021</td>\n",
       "      <td>15.664480</td>\n",
       "      <td>8.856082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>32.444118</td>\n",
       "      <td>17.341442</td>\n",
       "      <td>15.321165</td>\n",
       "      <td>7.036713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tamanio   Honduras     México  Rep. Dominicana    Uruguay\n",
       "0        1   5.153600   9.242860        12.293994  19.679599\n",
       "1        2  10.046661  15.038548        16.486744  26.300074\n",
       "2        3  15.484209  18.716443        19.655375  20.714957\n",
       "3        4  18.804112  22.618685        20.578243  17.412574\n",
       "4        5  18.067299  17.042021        15.664480   8.856082\n",
       "5        6  32.444118  17.341442        15.321165   7.036713"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos nuevas columnas con la cantidad de miembros por hogar y una clasificacion de tamaño\n",
    "df_total = {'tamanio': [1, 2, 3, 4, 5, 6]}\n",
    "df_total = pd.DataFrame(data=df_total)\n",
    "c = 0\n",
    "for name in df_todos:\n",
    "    print(f'iteration{i}: {style.green}{name}{style.endc}')\n",
    "    df = df_todos[name]\n",
    "    df = df.sort_values(by=['id']).reset_index()\n",
    "    df[\"tag_hogar\"] = df.groupby('id').cumcount() == 0\n",
    "    df['aux'] = 1 \n",
    "    df['miembros']=df.groupby('id')['aux'].transform(sum)\n",
    "\n",
    "    df[\"tamanio\"]=0\n",
    "    df.loc[(df[\"miembros\"]==1) & (df[\"tag_hogar\"] == True),\"tamanio\"]= 1 #Hogar unipersonal\n",
    "    df.loc[(df[\"miembros\"]==2) & (df[\"tag_hogar\"] == True),\"tamanio\"]= 2 #Hogar de dos personas\n",
    "    df.loc[(df[\"miembros\"]==3) & (df[\"tag_hogar\"] == True),\"tamanio\"]= 3 #Hogar de tres personas\n",
    "    df.loc[(df[\"miembros\"]==4) & (df[\"tag_hogar\"] == True),\"tamanio\"]= 4 #Hogar de cuatro personas\n",
    "    df.loc[(df[\"miembros\"]==5) & (df[\"tag_hogar\"] == True),\"tamanio\"]= 5 #Hogar de cinco personas\n",
    "    df.loc[(df[\"miembros\"]>=6) & (df[\"tag_hogar\"] == True),\"tamanio\"]= 6 #Hogar de seis personas o mas\n",
    "    \n",
    "    # Creamos un nuevo data frame con la cantidad de observaciones para cada categoria de tamaño y su porcentaje respecto al total\n",
    "    df_agg = df[df['tag_hogar'] == True] # Nos quedamos solo con un miembro del hogar\n",
    "    df_agg = df_agg[df_agg['tamanio']>0] # Descartamos las observaciones con valor igual a 0\n",
    "    df_agg = df_agg.groupby(by=['tamanio']).agg({'pondera':'sum'}) \n",
    "    df_agg['porcentaje'] = df_agg['pondera']/df_agg[\"pondera\"].sum()*100\n",
    "    df_agg.columns = ['total', cnt[c]]\n",
    "    df_total = df_total.merge(df_agg[cnt[c]], on = 'tamanio')\n",
    "    c += 1\n",
    "# verificamos resultado post iteración en bucle\n",
    "df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Distribución intrahogar\n",
    "\n",
    "[***Páginas 157***](https://drive.google.com/file/d/1MwQrMylnYL0VHrLRM3JafsCBE9NkisAJ/view)\n",
    "\n",
    "El fragmento de código siguiente puede utilizarse para generar resultados similares a los presentados en el cuadro 3.7 del texto, que muestra cómo se modifica la desigualdad calculada a través del cociente de deciles extremos cuando cambia la distribución del ingreso hacia el interior del hogar. Cabe recordar que la distribución del ingreso intrahogar se modifica mediante un impuesto proporcional al ingreso per cápita familiar combinado, con un subsidio que solo recibe el jefe de hogar. En la implementación, utilizamos quintiles en lugar de deciles ingreso. \n",
    "\n",
    "Para esta sección trabajaremos con diferentes bases nuevamente, por lo que podríamos pensar si no nos serviría una función que importe los países de interés. Sabemos hasta ahora que todas las bases corresponden a países en años específicos en formato *.dta*. Así que podríamos utilizar lo visto hasta ahora para crear una nueva función `import_dta()` cuyos argumentos sean los países que interesan y el/los años. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dta(cnt, year):\n",
    "    # list of possible countries \n",
    "    countries = {'argentina_92':\"1ICi2BF3YkQt2a_fBkxt00CV1_ipmsEIP\",\n",
    "                'argentina_06':\"194pyYGovurVuCw8zpfqe2dJ7XAbYdG4s\",\n",
    "                'argentina2_06':\"1IiHzxWrO-5dETM-jdiXx9ayP5PAqU0Yp\",\n",
    "                'honduras_06':\"1pLly5AnoWj9fPyBcBZ8bCgDWqZ1eppgD\",\n",
    "                'mexico_06':\"1udEv9SNL9IiOCmfXg8MLdru1v9C_Sds2\",\n",
    "                'republica_dominicana_06':\"1BxiFvCMrUSjDsgYs73-1yi2cGMuKJV22\",\n",
    "                'uruguay_06':\"1XI6dexijKCd2jIZlyZfV6C9sAU2mq39y\",\n",
    "                'ecuador_06':\"1fgHKvdLDe3x5tCQheoXRL1JMGNDW0W7n\",\n",
    "                'nicaragua_05':\"1ZBX4B4IrGPGIN9VwZLknaddCJ4AqAE07\",\n",
    "                'costa_rica_06':\"17Bq2ee5cSdV0N_tqj4yiuMmOfJaDJ_LD\",\n",
    "                'peru_06':\"1f5p2qF1N9tgqoQ-bdY8QMvzSnt2FCFWY\",\n",
    "                'panama_06':\"1-a7OTv-I6SJXDhFhrCixbitx7KT4_lgx\",\n",
    "                'paraguay_07':\"1DdvUN2auRHyDHX49gLpyBKD_mvulQpqN\",\n",
    "                'venezuela_06':\"1En_N99oLlbDlQU1X60NLnBNKRXq8waUi\",\n",
    "                'bolivia_05':\"1O4KAVOLNy9FCgW-YhPu8hkAQJ_kLgVr9\",\n",
    "                'brasil_07':\"1uWBruRaNYDSy7LrYWFw8cQ1wQCQn80RA\",\n",
    "                'colombia_06':\"1YNoQiSiHI3iGuHds7dsrcPVR6_eR_FaF\"} \n",
    "    # creating list of actual countries requested\n",
    "    li = []\n",
    "    for r in range(0, len(cnt)):\n",
    "        cnt[r] = cnt[r].replace(' ', '_')\n",
    "        if type(year[r]) == list:\n",
    "            for i in year[r]:\n",
    "                cntName = [f'{cnt[r]}_{i}']\n",
    "                li = li + cntName\n",
    "        else:\n",
    "            cntName = [f'{cnt[r]}_{year[r]}']\n",
    "            li = li + cntName\n",
    "    # main loop with the actual countries\n",
    "    df_todos = {}\n",
    "    c = 1\n",
    "    for name in li:\n",
    "        print(f'iteration {c}: {style.green}{name}{style.endc}')\n",
    "        if name == 'argentina_92':\n",
    "            df_todos[name] = pd.read_stata('https://drive.google.com/uc?id=' + countries[name], convert_categoricals=False) \n",
    "        else:\n",
    "            df_todos[name] = pd.read_stata('https://drive.google.com/uc?id=' + countries[name], convert_categoricals=False) \n",
    "        time.sleep(4) # restringimos la velocidad de cada query  \n",
    "        c+=1\n",
    "    return df_todos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos probar si funciona, creando una lista de países y una lista de años. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1: \u001b[1;32margentina_06\u001b[0m\n",
      "iteration 2: \u001b[1;32mhonduras_06\u001b[0m\n",
      "iteration 3: \u001b[1;32mparaguay_07\u001b[0m\n",
      "iteration 4: \u001b[1;32mvenezuela_06\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bases de Argentina, Honduras, Paraguay y Venezuela (2006)\n",
    "paises = ['argentina', 'honduras', 'paraguay', 'venezuela']\n",
    "y = ['06', '06', '07', '06']\n",
    "df_todos = import_dta(cnt=paises, year=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos una función que acepta lista de países y de años para importar y cargar cada *dataset* dentro de un diccionario. La función es mutable, iremos agregando bases a las opciones a medida que avancemos en el desarrollo del anexo y mejorando la misma en términos de prolijidad y estructura. Claramente, la función es mejorable y pensar en escenarios donde la misma no funcione resulta un buen ejercicio para mejorarla. A continuación, trabajaremos con las bases importadas en la rutina de arriba. \n",
    "\n",
    "Una vez cargadas las bases, creamos el objeto *ty_todos* que toma valores de diferentes tasas del impuesto aplicada sobre el *ipcf*. Teniendo esta lista realizamos un bucle sobre cada impuesto y cada país utilizado aplicando el siguiente procedimiento:\n",
    "1. ordenamos las observaciones por *id*\n",
    "2. identificamos al primer miembro del hogar\n",
    "3. creamos la variable impuesto, que va a ser la alícuota *ty* que se multiplica al *ipcf* \n",
    "4. creamos *subsidio*, que se calcula sumando por hogar la recaudación de impuestos, es decir, sumamos la variable *impuesto* por hogar\n",
    "5. seteamos a cero el valor del subsidio para todos los miembros del hogar distintos al primero, de esta manera, el subsidio solo lo recibe un integrante\n",
    "6. creamos una variable para el nuevo valor de ingreso per cápita familiar, restando el impuesto y sumando el subsidio\n",
    "7. hacemos uso de nuestra función `ratq51` para computar el cociente del ingreso promedio de los quintiles 5 y 1 como indicador de desigualdad, a partir del ingreso modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos listas con las bases para las que vamos a calcular el cociente de quintiles y las alicuotas del impuesto simulado\n",
    "ty_todos = [0, 0.1, 0.2, 0.3]\n",
    "# Armamos un dataframe vacio para almacenar los resultados\n",
    "results = pd.DataFrame()\n",
    "# Rellenamos el dataframe con los cocientes de quintiles para cada combinacion de pais y alicuota\n",
    "j = 0\n",
    "for ty in ty_todos:\n",
    "    for name in df_todos.keys():\n",
    "        df = df_todos[name]\n",
    "        df = df.sort_values(by=['id']).reset_index()\n",
    "        df[\"tag_hogar\"] = df.groupby('id').cumcount() == 0\n",
    "        df[\"impuesto\"] = df[\"ipcf\"]*ty\n",
    "        #Recaudacion impuesto por hogar:\n",
    "        df[\"subsidio\"] = df.groupby(['id']).impuesto.transform('sum')\n",
    "        df.loc[df[\"tag_hogar\"] != True,\"subsidio\"]= 0\n",
    "        df[\"ipcf_star\"] = df[\"ipcf\"] - df[\"impuesto\"] + df[\"subsidio\"]\n",
    "        results.loc[ty,j] = ratq51(data=df, x=\"ipcf_star\",weight=\"pondera\")\n",
    "        if j > 2:\n",
    "            j = j - 3\n",
    "        else:\n",
    "            j= j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Honduras</th>\n",
       "      <th>Paraguay</th>\n",
       "      <th>Venezuela</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>30.353247</td>\n",
       "      <td>13.434139</td>\n",
       "      <td>14.290753</td>\n",
       "      <td>11.411448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>31.697813</td>\n",
       "      <td>14.195312</td>\n",
       "      <td>15.037427</td>\n",
       "      <td>11.941979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>35.299732</td>\n",
       "      <td>16.056223</td>\n",
       "      <td>16.887499</td>\n",
       "      <td>13.339560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>40.956234</td>\n",
       "      <td>18.923555</td>\n",
       "      <td>19.819693</td>\n",
       "      <td>15.598350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Argentina   Honduras   Paraguay  Venezuela\n",
       "0.0  30.353247  13.434139  14.290753  11.411448\n",
       "0.1  31.697813  14.195312  15.037427  11.941979\n",
       "0.2  35.299732  16.056223  16.887499  13.339560\n",
       "0.3  40.956234  18.923555  19.819693  15.598350"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Asignamos nombres a las columnas y verificamos los resultados\n",
    "results.columns = ['Argentina', 'Honduras', 'Paraguay', 'Venezuela']\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Empleo de ponderadores\n",
    "\n",
    "[***Páginas 157***](https://drive.google.com/file/d/1MwQrMylnYL0VHrLRM3JafsCBE9NkisAJ/view)\n",
    "\n",
    "El bloque de código que sigue puede utilizarse para construir un cuadro como el 3.9 del texto, que muestra la relación entre el ingreso per cápita familiar y el valor de la variable de ponderación. En primer lugar, volvemos a descargar las bases que vamos a utilizar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1: \u001b[1;32margentina_06\u001b[0m\n",
      "iteration 2: \u001b[1;32mhonduras_06\u001b[0m\n",
      "iteration 3: \u001b[1;32mmexico_06\u001b[0m\n",
      "iteration 4: \u001b[1;32mnicaragua_05\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bases de Argentina, Honduras, Paraguay y Venezuela (2006)\n",
    "paises = ['argentina', 'honduras', 'mexico', 'nicaragua']\n",
    "y = ['06', '06', '06', '05']\n",
    "df_todos = import_dta(cnt=paises, year=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con las bases ya cargadas pasamos a realizar el siguiente procedimiento, en un bucle para los países:\n",
    "1. ordenamos por *id*\n",
    "2. generamos la variable *shrpop*\n",
    "3. identificamos el quintil de la observación según *shrpop*, creando la variable *quintil*\n",
    "4. calculamos el valor promedio del factor de expansión agrupando por *quintil* previamente\n",
    "5. unimos el resultado al *dataframe* *df_total* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration1: \u001b[1;32margentina_06\u001b[0m\n",
      "iteration2: \u001b[1;32mhonduras_06\u001b[0m\n",
      "iteration3: \u001b[1;32mmexico_06\u001b[0m\n",
      "iteration4: \u001b[1;32mnicaragua_05\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Creamos un data frame para ir almacenando los datos de cada pais\n",
    "df_total = {'quintil': [1, 2, 3, 4, 5]}\n",
    "df_total = pd.DataFrame(data=df_total)\n",
    "# # Rellenamos el data frame con el valor de ponderacion promedio por quintil para cada pais\n",
    "# df_todos = [df_arg, df_cri, df_mex, df_nic]\n",
    "\n",
    "i=1\n",
    "for name in df_todos.keys():\n",
    "    print(f'iteration{i}: {style.green}{name}{style.endc}')\n",
    "    df = df_todos[name]\n",
    "    df= df.sort_values(by=['ipcf']).reset_index()\n",
    "    df[\"shrpop\"]= df[\"pondera\"].cumsum()\n",
    "    df[\"shrpop\"]= df[\"shrpop\"]/ df[\"pondera\"].sum()\n",
    "    \n",
    "    df[\"quintil\"]=0\n",
    "    df.loc[df[\"shrpop\"] <= 0.2,\"quintil\"]=1\n",
    "    df.loc[(df[\"shrpop\"] <= 0.4) & (df[\"shrpop\"] > 0.2),\"quintil\"]=2\n",
    "    df.loc[(df[\"shrpop\"] <= 0.6) & (df[\"shrpop\"] > 0.4),\"quintil\"]=3\n",
    "    df.loc[(df[\"shrpop\"] <= 0.8) & (df[\"shrpop\"] > 0.6),\"quintil\"]=4\n",
    "    df.loc[(df[\"shrpop\"] <= 1) & (df[\"shrpop\"] > 0.8),\"quintil\"]=5\n",
    "    df_agg = df.groupby(by=['quintil']).agg({'pondera':'mean'}) \n",
    "    df_total = df_total.merge(df_agg['pondera'], on = 'quintil')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quintil</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Costa Rica</th>\n",
       "      <th>Mexico</th>\n",
       "      <th>Nicaragua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>212.469803</td>\n",
       "      <td>83.344233</td>\n",
       "      <td>1067.922660</td>\n",
       "      <td>114.630926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>230.594847</td>\n",
       "      <td>79.286837</td>\n",
       "      <td>1251.622716</td>\n",
       "      <td>129.206679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>225.251378</td>\n",
       "      <td>73.965157</td>\n",
       "      <td>1366.020942</td>\n",
       "      <td>141.302370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>238.843591</td>\n",
       "      <td>69.881563</td>\n",
       "      <td>1352.518184</td>\n",
       "      <td>160.510099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>238.079130</td>\n",
       "      <td>65.818807</td>\n",
       "      <td>1317.389374</td>\n",
       "      <td>170.100365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quintil   Argentina  Costa Rica       Mexico   Nicaragua\n",
       "0        1  212.469803   83.344233  1067.922660  114.630926\n",
       "1        2  230.594847   79.286837  1251.622716  129.206679\n",
       "2        3  225.251378   73.965157  1366.020942  141.302370\n",
       "3        4  238.843591   69.881563  1352.518184  160.510099\n",
       "4        5  238.079130   65.818807  1317.389374  170.100365"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Asignamos nombres a las columnas y verificamos los resultados\n",
    "df_total.columns = ['Quintil', 'Argentina', 'Honduras', 'Mexico', 'Nicaragua']\n",
    "df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente se calculan las tasas de pobreza con y sin ponderadores para cada una de las regiones de México en 2006, correspondientes al cuadro 3.10 del texto. En la primer línea el objeto \"lp\" almacena el valor de la línea de pobreza, en base a la cual se genera la variable binaria *pobreza*, que vale 1 para los individuos debajo de este umbral (es decir, `ipcf < lp`) y 0 para el resto. Al computar el promedio de esta variable obtenemos la proporción de personas por debajo de la línea de la pobreza, la misma se realiza con y sin ponderador para cada una de las regiones, en un bucle para las 9 regiones de México. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos la base de Mexico de 2006\n",
    "df_mex = df_todos['mexico_06']\n",
    "# Establecemos una linea de pobreza y añadimos una columna a la base de datos con una variable que vale 1 si el IPCF de un \n",
    "# individuo es inferior a esa linea y 0 en caso contrario. \n",
    "lp = 633.90918\n",
    "df_mex[\"pobreza\"] = (df_mex[\"ipcf\"] < lp) * 1\n",
    "# Creamos un dataframe para almacenar las tasas de pobreza por region \n",
    "tasas_pobreza = {'region': ['Noroeste', 'Norte', 'Noreste', 'Centro-Occidente', 'Centro-Este', 'Sur', 'Oriente', 'Peninsula de Yucatan', 'Nacional']}\n",
    "tasas_pobreza = pd.DataFrame(data=tasas_pobreza)\n",
    "tasas_pobreza['pob_sin_pond'] = 0\n",
    "tasas_pobreza['pob_pond'] = 0\n",
    "\n",
    "# Rellenamos el dataframe con las tasas de pobreza\n",
    "j = 0\n",
    "for i in range(1,9): \n",
    "    df_mex_1 = df_mex[df_mex['region'] == i].copy()\n",
    "    pondera_1 = df_mex_1[\"pondera\"]\n",
    "    tasas_pobreza.loc[j, 'pob_sin_pond'] = np.average(df_mex_1[\"pobreza\"])\n",
    "    tasas_pobreza.loc[j, 'pob_pond'] = np.average(df_mex_1[\"pobreza\"],weights=pondera_1)   \n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Pobreza sin ponderador</th>\n",
       "      <th>Pobreza con ponderador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Noroeste</td>\n",
       "      <td>0.099922</td>\n",
       "      <td>0.096917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Norte</td>\n",
       "      <td>0.186734</td>\n",
       "      <td>0.133521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noreste</td>\n",
       "      <td>0.114403</td>\n",
       "      <td>0.063756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Centro-Occidente</td>\n",
       "      <td>0.125055</td>\n",
       "      <td>0.131974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Centro-Este</td>\n",
       "      <td>0.148284</td>\n",
       "      <td>0.107151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sur</td>\n",
       "      <td>0.456111</td>\n",
       "      <td>0.359241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Oriente</td>\n",
       "      <td>0.223839</td>\n",
       "      <td>0.218525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Peninsula de Yucatan</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.157331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nacional</td>\n",
       "      <td>0.188186</td>\n",
       "      <td>0.148160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Region  Pobreza sin ponderador  Pobreza con ponderador\n",
       "0              Noroeste                0.099922                0.096917\n",
       "1                 Norte                0.186734                0.133521\n",
       "2               Noreste                0.114403                0.063756\n",
       "3      Centro-Occidente                0.125055                0.131974\n",
       "4           Centro-Este                0.148284                0.107151\n",
       "5                   Sur                0.456111                0.359241\n",
       "6               Oriente                0.223839                0.218525\n",
       "7  Peninsula de Yucatan                0.198000                0.157331\n",
       "8              Nacional                0.188186                0.148160"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos la tasa de pobreza nacional y verificamos los datos\n",
    "pondera = df_mex[\"pondera\"]\n",
    "tasas_pobreza.loc[8, 'pob_sin_pond'] = np.average(df_mex[\"pobreza\"])\n",
    "tasas_pobreza.loc[8, 'pob_pond'] = np.average(df_mex[\"pobreza\"], weights=pondera) \n",
    "tasas_pobreza.columns = ['Region', 'Pobreza sin ponderador', 'Pobreza con ponderador']\n",
    "tasas_pobreza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Diseño muestral\n",
    "\n",
    "[***Páginas 160***](https://drive.google.com/file/d/1MwQrMylnYL0VHrLRM3JafsCBE9NkisAJ/view)\n",
    "\n",
    "En este apartado se muestra cómo puede considerarse la estructura muestral al momento de computar un indicador relativamente sencillo; ver cuadro 3.11 del texto del capítulo. A modo de ejemplo, se emplea la Encuesta de Hogares de Propósitos Múltiples (EHPM) de Costa Rica para el año 2006 para calcular la proporción de trabajadores empleados en las industrias alimenticia y textil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1: \u001b[1;32mcosta_rica_06\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Importamos la base de Costa Rica para 2006\n",
    "paises = ['costa rica']\n",
    "y = ['06']\n",
    "df_todos = import_dta(cnt=paises, year=y)\n",
    "df_cri = df_todos['costa_rica_06']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se generan quintiles de ingreso laboral (variable *ila*) para los individuos\n",
    "ocupados y que declaran sector de empleo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducimos la muestra a los ocupados sin valores faltantes en las variables 'sector' e 'ila'\n",
    "df_cri = df_cri[df_cri['ocupado'] == 1].copy()\n",
    "df_cri = df_cri.dropna(subset=['sector'])\n",
    "df_cri = df_cri.dropna(subset=['ila'])\n",
    "\n",
    "# Creamos quintiles en base al ingreso laboral de los ocupados\n",
    "df_cri= df_cri.sort_values(by=['ila']).reset_index()\n",
    "df_cri[\"shrpop\"]= df_cri[\"pondera\"].cumsum()\n",
    "df_cri[\"shrpop\"]= df_cri[\"shrpop\"]/ df_cri[\"pondera\"].sum()\n",
    "    \n",
    "df_cri[\"quintil\"]=0\n",
    "df_cri.loc[df_cri[\"shrpop\"] <= 0.2,\"quintil\"]=1\n",
    "df_cri.loc[(df_cri[\"shrpop\"] <= 0.4) & (df_cri[\"shrpop\"] > 0.2),\"quintil\"]=2\n",
    "df_cri.loc[(df_cri[\"shrpop\"] <= 0.6) & (df_cri[\"shrpop\"] > 0.4),\"quintil\"]=3\n",
    "df_cri.loc[(df_cri[\"shrpop\"] <= 0.8) & (df_cri[\"shrpop\"] > 0.6),\"quintil\"]=4\n",
    "df_cri.loc[(df_cri[\"shrpop\"] <= 1) & (df_cri[\"shrpop\"] > 0.8),\"quintil\"]=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, la variable lowtec que vale 1 para los individuos empleados en las industrias alimenticia y textil (variable *sector=2*), 0 para los trabajadores empleados en otros sectores, y missing para quienes no tienen asignado un quintil de ingreso laboral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos una variable que indique si el sector corresponde a una industria de baja tecnologia\n",
    "df_cri['lowtec'] = (df_cri[\"sector\"] == 2) * 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estratificación de la **EHPM** de Costa Rica emplea dos criterios: región y zona urbana o rural. Por lo tanto, es necesario crear la variable de estratificación que permita identificar a cuál de los estratos pertenece cada observación de la encuesta. Utilizamos `econtools.group_id` para generar la variable *estrato*, que identifica con un número a cada uno de los \"grupos\" diferentes en que puede dividirse la base de datos al combinar las variables que recibe como argumento. El primero de los grupos recibe el número 1, el segundo grupo recibe el número 2, y así sucesivamente. Lueog, calculamos la proporción de ocupados en industria de baja tecnologia por quintil, junto con su desvío y error estándar y la cantidad de observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generamos una nueva variable que agrupe las variables 'region' y 'urbano'\n",
    "df_cri = econtools.group_id(df_cri, cols=['region', 'urbano'], merge = True)\n",
    "df_cri = df_cri.rename(columns={'group_id': 'estrato'})\n",
    "# computos por quintil\n",
    "df_agg = df_cri.groupby(by=['quintil']).agg({'lowtec':['mean', 'std', 'count']}) \n",
    "df_agg.reset_index(inplace=True)  \n",
    "df_agg.columns = list(map(''.join, df_agg.columns.values))\n",
    "df_agg.columns = ['Quintil', 'Media', 'Desvio', 'N']\n",
    "df_agg['Error estandar'] = df_agg['Desvio']/(df_agg['N'])**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quintil</th>\n",
       "      <th>Media</th>\n",
       "      <th>Desvio</th>\n",
       "      <th>N</th>\n",
       "      <th>Error estandar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.066213</td>\n",
       "      <td>0.248687</td>\n",
       "      <td>3670</td>\n",
       "      <td>0.004105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.072895</td>\n",
       "      <td>0.260003</td>\n",
       "      <td>3361</td>\n",
       "      <td>0.004485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.073270</td>\n",
       "      <td>0.260616</td>\n",
       "      <td>3453</td>\n",
       "      <td>0.004435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.066368</td>\n",
       "      <td>0.248961</td>\n",
       "      <td>3345</td>\n",
       "      <td>0.004305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.045486</td>\n",
       "      <td>0.208403</td>\n",
       "      <td>2902</td>\n",
       "      <td>0.003869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quintil     Media    Desvio     N  Error estandar\n",
       "0        1  0.066213  0.248687  3670        0.004105\n",
       "1        2  0.072895  0.260003  3361        0.004485\n",
       "2        3  0.073270  0.260616  3453        0.004435\n",
       "3        4  0.066368  0.248961  3345        0.004305\n",
       "4        5  0.045486  0.208403  2902        0.003869"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizamos\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, realizamos el mismo ejercicio pero incluyendo a los ponderadores. Para ello, con la variable *quintil* ya creada realizamos un bucle filtrando en cada instancia el quintil de interés, donde se realizan los mismos cálculos realizados antes. Una vez realizado el cálculo de la media y el desvío estándar le agregamos los dos estadísticos que faltan, el error estándar y la cantidad de observaciones.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quintil</th>\n",
       "      <th>Media</th>\n",
       "      <th>Desvio</th>\n",
       "      <th>N</th>\n",
       "      <th>Error estandar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.067483</td>\n",
       "      <td>0.250857</td>\n",
       "      <td>3670</td>\n",
       "      <td>0.004141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.085692</td>\n",
       "      <td>0.279909</td>\n",
       "      <td>3361</td>\n",
       "      <td>0.004828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.072924</td>\n",
       "      <td>0.260011</td>\n",
       "      <td>3453</td>\n",
       "      <td>0.004425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.060119</td>\n",
       "      <td>0.237708</td>\n",
       "      <td>3345</td>\n",
       "      <td>0.004110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.045484</td>\n",
       "      <td>0.208364</td>\n",
       "      <td>2902</td>\n",
       "      <td>0.003868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quintil     Media    Desvio     N  Error estandar\n",
       "0        1  0.067483  0.250857  3670        0.004141\n",
       "1        2  0.085692  0.279909  3361        0.004828\n",
       "2        3  0.072924  0.260011  3453        0.004425\n",
       "3        4  0.060119  0.237708  3345        0.004110\n",
       "4        5  0.045484  0.208364  2902        0.003868"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe vacio para ir colocando los valores\n",
    "df_pondera = {'Quintil': [1, 2, 3, 4, 5], 'Media': [0, 0, 0, 0, 0], 'Desvio': [0, 0, 0, 0, 0]}\n",
    "df_pondera = pd.DataFrame(data=df_pondera)\n",
    "\n",
    "# Rellenamos el dataframe\n",
    "j = 0\n",
    "for i in range(1,6): \n",
    "\n",
    "    df_cri_1 = df_cri[df_cri['quintil'] == i].copy()\n",
    "    lowtec_1 = df_cri_1[\"lowtec\"]\n",
    "    pondera_1 = df_cri_1[\"pondera\"]\n",
    "    media_1 = np.average(lowtec_1, weights=pondera_1)  \n",
    "    var_1 = np.average((lowtec_1-media_1)**2, weights=pondera_1) \n",
    "    de_1 = math.sqrt(var_1)\n",
    "    df_pondera.loc[j, 'Media'] = media_1\n",
    "    df_pondera.loc[j, 'Desvio'] = de_1\n",
    "    j = j + 1\n",
    "# Agregamos columnas con el numero de observaciones y el error estandar y verificamos\n",
    "N = df_agg.drop(['Media', 'Desvio', 'Error estandar'], axis=1)\n",
    "df_pondera = df_pondera.merge(N, on = 'Quintil')\n",
    "df_pondera['Error estandar'] = df_pondera['Desvio']/(df_pondera['N'])**(1/2)\n",
    "# visualizamos\n",
    "df_pondera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Fuentes de ingreso\n",
    "\n",
    "[***Páginas 161***](https://drive.google.com/file/d/1MwQrMylnYL0VHrLRM3JafsCBE9NkisAJ/view)\n",
    "\n",
    "El bloque de código a continuación muestra cómo computar la importancia que tiene cada fuente de ingresos identificada en las encuestas de hogares (cuadro 3.13). Dentro de las fuentes de ingreso consideramos: laboral (variable *ila*), jubilaciones (*ijubi*), capital (*icap*), transferencias (*itran*) y otros (*ionl*). En primer lugar, cargamos las bases de los países que vamos a utilizar. Luego, utilizando un bucle para cada país realizamos el siguiente procedimiento:\n",
    "1. generamos la variable ingreso total (*itot*), como la suma de las columnas para cada ingreso\n",
    "2. a cada fuente de ingreso la multiplicamos por el factor de expansión *pondera*\n",
    "3. creamos las variables de participación en el ingreso calculando el ratio de cada concepto sobre el ingreso total\n",
    "4. repetimos para cada país y visualizamos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1: \u001b[1;32margentina2_06\u001b[0m\n",
      "iteration 2: \u001b[1;32mbolivia_05\u001b[0m\n",
      "iteration 3: \u001b[1;32mcolombia_06\u001b[0m\n",
      "iteration 4: \u001b[1;32mrepublica_dominicana_06\u001b[0m\n",
      "iteration 5: \u001b[1;32muruguay_06\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Cargamos las bases de Argentina, Bolivia, Colombia, R. Dominicana y Uruguay (circa 2007)\n",
    "# Importamos la base de Costa Rica para 2006\n",
    "paises = ['argentina2','bolivia','colombia','republica dominicana','uruguay']\n",
    "y = ['06','05','06','06','06']\n",
    "\n",
    "\n",
    "df_todos = import_dta(cnt=paises, year=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un dataframe para almacenar los resultados\n",
    "results = pd.DataFrame(columns = ['Pais', 'Año', 'Laborales', 'Capital', 'Transferencias'])\n",
    "results['Pais'] = ['Argentina', 'Bolivia', 'Colombia', 'R. Dominicana', 'Uruguay']\n",
    "results['Año'] = ['2006', '2005', '2006', '2006', '2006']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: \u001b[1;32margentina2_06\u001b[0m\n",
      "iteration: \u001b[1;32mbolivia_05\u001b[0m\n",
      "iteration: \u001b[1;32mcolombia_06\u001b[0m\n",
      "iteration: \u001b[1;32mrepublica_dominicana_06\u001b[0m\n",
      "iteration: \u001b[1;32muruguay_06\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pais</th>\n",
       "      <th>Año</th>\n",
       "      <th>Laborales</th>\n",
       "      <th>Capital</th>\n",
       "      <th>Transferencias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.804241</td>\n",
       "      <td>0.014984</td>\n",
       "      <td>0.16988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolivia</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.812866</td>\n",
       "      <td>0.060155</td>\n",
       "      <td>0.126979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.859099</td>\n",
       "      <td>0.029561</td>\n",
       "      <td>0.120585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R. Dominicana</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.758765</td>\n",
       "      <td>0.032284</td>\n",
       "      <td>0.190043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uruguay</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.695131</td>\n",
       "      <td>0.033091</td>\n",
       "      <td>0.271777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pais   Año Laborales   Capital Transferencias\n",
       "0      Argentina  2006  0.804241  0.014984        0.16988\n",
       "1        Bolivia  2005  0.812866  0.060155       0.126979\n",
       "2       Colombia  2006  0.859099  0.029561       0.120585\n",
       "3  R. Dominicana  2006  0.758765  0.032284       0.190043\n",
       "4        Uruguay  2006  0.695131  0.033091       0.271777"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rellenamos el dataframe\n",
    "j = 0\n",
    "for name in df_todos.keys():\n",
    "    print(f'iteration: {style.green}{name}{style.endc}')\n",
    "    df = df_todos[name]\n",
    "    df['itot'] = df.fillna(0)['ila'] + df.fillna(0)['ijubi'] + df.fillna(0)['icap'] + df.fillna(0)['itran'] + df.fillna(0)['ionl'] \n",
    "    ila = np.sum(df['ila']*df['pondera'])\n",
    "    ijubi = np.sum(df['ijubi']*df['pondera'])\n",
    "    icap = np.sum(df['icap']*df['pondera'])\n",
    "    itran = np.sum(df['itran']*df['pondera'])\n",
    "    ionl = np.sum(df['ionl']*df['pondera'])\n",
    "    itot = np.sum(df['itot']*df['pondera'])\n",
    "    \n",
    "    results.loc[j, 'Laborales'] = ila/itot\n",
    "    results.loc[j, 'Capital'] = icap/itot\n",
    "    results.loc[j, 'Transferencias'] = (ijubi + itran)/itot\n",
    "    \n",
    "    j = j + 1 \n",
    "\n",
    "#Verificamos que los datos se hayan cargado correctamente\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "110fe3fb9777db4ce1f884af3cc527a40b2c98427ad17781c021ef692bd3d28d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}